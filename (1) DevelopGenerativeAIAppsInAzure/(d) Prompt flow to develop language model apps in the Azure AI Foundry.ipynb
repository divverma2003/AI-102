{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPICXT1iis7WYi5kRP1ouCz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Introduction to Prompt Flow**\n","\n","---\n","\n","## Overview\n","Prompt flow enables developers to develop, test, tune, and deploy LLM applications by combining data sources with Large Language Models.\n","\n","**Platform Access**: Azure Machine Learning Studio and Azure AI Foundry Portal\n","\n","## Core Concepts\n","\n","### Prompts\n","**Definition**: Query or instructions provided to an LLM application to generate a response\n","\n","**Effectiveness depends on**:\n","- How well it conveys user intent\n","- Clarity of desired outcome\n","\n","**Examples**:\n","- Text generation: \"Write a product description for...\"\n","- Question-answering: \"What are the benefits of...?\"\n","\n","### Flows\n","**Definition**: Sequence of actions or steps to achieve a specific task\n","\n","**Flow Journey**:\n","1. Receiving input\n","2. Processing through LLM interaction\n","3. Generating output or performing desired action\n","\n","## Key Capabilities\n","\n","### Development Lifecycle\n","- **Develop**: Create and design LLM application flows\n","- **Test**: Validate application behavior and outputs\n","- **Tune**: Optimize prompts and flow performance\n","- **Deploy**: Move applications to production\n","\n","### Use Cases\n","- Classify web pages into categories\n","- Build chatbots on custom data\n","- Generate content based on data sources\n","- Automate tasks using LLM capabilities\n","\n","## Flow Design\n","\n","### Input-Process-Output Model\n","- **Input**: User prompts and data sources\n","- **Process**: Flow execution with LLM interaction\n","- **Output**: Generated responses or completed actions\n","\n","### Key Components\n","- Data retrieval and preprocessing\n","- LLM interaction and inference\n","- Response formatting and validation\n","- Error handling and fallbacks\n","\n","## Prompt Effectiveness Factors\n","- **Clarity**: Clearly convey user intent\n","- **Specificity**: Define desired outcome precisely\n","- **Context**: Provide relevant background information\n","- **Structure**: Organize instructions logically\n","\n","## Key Takeaway\n","Prompt flow provides a comprehensive platform for developing LLM applications by orchestrating the interaction between prompts, data sources, and language models through structured flows. Supports full development lifecycle across Azure ML Studio and Azure AI Foundry Portal."],"metadata":{"id":"IgXLBO4M1aG9"}},{"cell_type":"markdown","source":["# **Development lifecycle of a large language model (LLM) app**\n","---\n","## Four Lifecycle Stages\n","\n","### 1. Initialization\n","**Purpose**: Define use case and design solution\n","\n","**Four Steps**:\n","1. Define the objective\n","2. Collect a sample dataset\n","3. Build a basic prompt\n","4. Design the flow\n","\n","**Sample Dataset Requirements**:\n","- Small representative subset of expected input data\n","- Ensure diversity to cover various scenarios and edge cases\n","- Remove privacy-sensitive information\n","\n","**Example**: News article classification - define categories, understand article format, determine input/output structure\n","\n","### 2. Experimentation\n","**Purpose**: Develop flow and test with small dataset\n","\n","**Iterative Process** (4 steps):\n","1. Run flow against sample dataset\n","2. Evaluate prompt's performance\n","3. If satisfied → move to evaluation and refinement\n","4. If not satisfied → modify flow (change prompt or flow structure)\n","\n","**Key Characteristic**: Continuous iteration until results are satisfactory\n","\n","### 3. Evaluation and Refinement\n","**Purpose**: Assess flow with larger dataset\n","\n","**Activities**:\n","- Test flow performance on larger dataset\n","- Evaluate how well application generalizes to new data\n","- Identify potential bottlenecks or optimization areas\n","\n","**Best Practice**: After editing flow, test with smaller dataset first before running against larger dataset for faster issue identification\n","\n","**Decision Point**: When application is robust and reliable → move to production\n","\n","### 4. Production\n","**Purpose**: Deploy and monitor flow and application\n","\n","**Three Steps**:\n","1. **Optimize**: Enhance flow for efficiency and effectiveness\n","2. **Deploy**: Deploy flow to endpoint (calling endpoint triggers flow execution)\n","3. **Monitor**: Collect usage data and end-user feedback for continuous improvement\n","\n","## Lifecycle Flow Pattern\n","\n","**Forward Movement**:\n","Initialization → Experimentation → Evaluation & Refinement → Production\n","\n","**Backward Iteration**:\n","- From Evaluation & Refinement → back to Experimentation (if improvements needed)\n","- From Production → back to Experimentation (if monitoring reveals issues)\n","\n","## Key Concepts by Stage\n","\n","### Initialization Focus\n","- Clear objective definition\n","- Representative sample data\n","- Basic prompt creation\n","- Initial flow design\n","\n","### Experimentation Focus\n","- Rapid testing and iteration\n","- Prompt performance evaluation\n","- Flow modification based on results\n","- Small dataset validation\n","\n","### Evaluation & Refinement Focus\n","- Large-scale testing\n","- Generalization assessment\n","- Performance bottleneck identification\n","- Incremental testing after modifications\n","\n","### Production Focus\n","- Efficiency optimization\n","- Endpoint deployment\n","- Performance monitoring\n","- Continuous improvement based on real-world usage\n","\n","## Testing Strategy\n","\n","### Small Dataset Testing\n","- Used during: Initialization and Experimentation\n","- Purpose: Quick validation and rapid iteration\n","- Allows: Faster response to issues\n","\n","### Large Dataset Testing\n","- Used during: Evaluation and Refinement\n","- Purpose: Assess generalization and robustness\n","- Validates: Real-world performance expectations\n","\n","## Key Takeaway\n","The LLM app development lifecycle is iterative, with four distinct stages. Applications can move backwards from later stages to Experimentation for continuous improvement. Start with small datasets for rapid iteration, then validate with larger datasets before production deployment."],"metadata":{"id":"lcG0MVU66vEe"}},{"cell_type":"markdown","source":["# **Understand core components and explore flow types**\n","---\n","## Flow Structure\n","\n","### Three Core Parts\n","1. **Inputs**: Data passed into the flow (strings, integers, boolean, etc.)\n","2. **Nodes**: Tools that perform data processing, task execution, or algorithmic operations\n","3. **Outputs**: Data produced by the flow\n","\n","**Node Connectivity**: Nodes can use flow inputs or outputs from other nodes (pipeline-like structure)\n","\n","## Common Tools\n","\n","### LLM Tool\n","**Purpose**: Custom prompt creation utilizing Large Language Models\n","**Use cases**: Text generation, classification, summarization\n","\n","### Python Tool\n","**Purpose**: Execute custom Python scripts\n","**Use cases**: Data processing, API calls, custom logic\n","\n","### Prompt Tool\n","**Purpose**: Prepare prompts as strings for complex scenarios or integration with other tools\n","**Use cases**: Prompt templating, dynamic prompt generation\n","\n","**Custom Tools**: Can create your own tools if needed functionality isn't available\n","\n","## Node Configuration\n","\n","### Node Components\n","- **Expected inputs**: Define what data the node receives\n","- **Expected outputs**: Define what data the node produces\n","- **Tool selection**: Choose which tool the node uses\n","\n","**Linking Nodes**: Nodes connect by using other nodes' outputs as their inputs\n","\n","## Three Flow Types\n","\n","### 1. Standard Flow\n","**Purpose**: General LLM-based application development\n","**Characteristics**: Versatile tools for various use cases\n","**Best for**: Most common LLM applications\n","\n","### 2. Chat Flow\n","**Purpose**: Conversational applications\n","**Characteristics**: Enhanced support for chat-related functionalities\n","**Best for**: Chatbots, conversational interfaces, multi-turn dialogs\n","\n","### 3. Evaluation Flow\n","**Purpose**: Performance evaluation\n","**Characteristics**: Analysis and improvement through feedback on previous runs\n","**Best for**: Testing and optimizing model/application performance\n","\n","## Key Concepts\n","\n","### Tool Reusability\n","- Multiple tools can be used within one flow\n","- Same tool can be used multiple times in different nodes\n","\n","### Flow Design Process\n","1. Define inputs\n","2. Add nodes with appropriate tools\n","3. Connect nodes by linking outputs to inputs\n","4. Define desired outputs\n","\n","## Key Takeaway\n","Prompt flows consist of inputs, nodes (tools), and outputs. Three flow types serve different purposes: Standard for general apps, Chat for conversations, and Evaluation for performance testing. Nodes can be linked together using various tools (LLM, Python, Prompt) to create complete LLM applications."],"metadata":{"id":"x5e3qrvA8TAF"}},{"cell_type":"markdown","source":["# **Connections and Runtimes**\n","---\n","## Connections\n","\n","### Purpose\n","Configure secure links between prompt flow and external services for data communication\n","\n","### Functionality\n","- Securely store endpoints, API keys, or credentials\n","- Secrets stored in Azure Key Vault (not exposed to users)\n","- Enable reusable external service access across flows\n","\n","### Connection Types and Required Tools\n","\n","| Connection Type | Built-in Tools |\n","|----------------|---------------|\n","| **Azure OpenAI** | LLM or Python |\n","| **OpenAI** | LLM or Python |\n","| **Azure AI Search** | Vector DB Lookup or Python |\n","| **Serp** | Serp API or Python |\n","| **Custom** | Python |\n","\n","### Two Key Use Cases\n","1. **API Credential Management**: Automate and secure handling of sensitive access information\n","2. **Secure Data Transfer**: Maintain data integrity and privacy across different environments\n","\n","## Runtimes\n","\n","### Definition\n","Combination of compute instance and environment needed to run flows\n","\n","### Three Components\n","1. **Runtime**: Overall execution environment\n","2. **Compute Instance**: Provides necessary compute resources\n","3. **Environment**: Specifies packages and libraries to be installed\n","\n","### Purpose\n","- Controlled environment for running and validating flows\n","- Ensures stable execution environment\n","- Validates flow functionality before deployment\n","\n","### Environment Types\n","\n","**Default Environment**:\n","- Available for quick development and testing\n","- Pre-configured with common packages\n","\n","**Custom Environment**:\n","- Created when additional packages needed\n","- Allows installation of specific libraries and dependencies\n","\n","## Configuration Workflow\n","\n","### Setup Process\n","1. Create connections to external services\n","2. Configure runtime with appropriate compute and environment\n","3. Run flow using configured runtime\n","4. Validate flow execution and outputs\n","\n","## Key Takeaway\n","Connections provide secure access to external services with credentials stored in Azure Key Vault, while runtimes combine compute instances and environments to execute flows in controlled, stable settings. Both are essential prerequisites for running prompt flows."],"metadata":{"id":"vgOI2KBVBqEu"}},{"cell_type":"markdown","source":["# **Explore variants and monitoring options**\n","\n","---\n","\n","## Variants\n","\n","### Definition\n","Versions of a tool node with distinct settings\n","\n","**Current Support**: LLM tool only\n","**Variants Can Represent**: Different prompt content or connection settings\n","\n","### Benefits\n","- **Enhance quality**: Create diverse variants to find best prompt and settings\n","- **Save time**: Easy management and comparison of prompt versions\n","- **Boost productivity**: Quickly create and manage variations for better results\n","- **Facilitate comparison**: Side-by-side result comparisons for data-driven decisions\n","\n","### Use Case Example\n","Customize approaches for specific tasks (e.g., summarizing news articles with different prompts)\n","\n","## Deployment to Endpoints\n","\n","### Online Endpoints\n","**Purpose**: Deploy flows for real-time access via API calls\n","\n","**Characteristics**:\n","- URLs that can be called from any application\n","- (Almost) immediate response to API calls\n","- Generated URL and key for secure integration\n","\n","### Use Cases\n","- Generate chat responses for applications\n","- Create agentic responses\n","- Integrate flows into business processes\n","- Real-time output delivery\n","\n","## Monitoring Evaluation Metrics\n","\n","### Purpose\n","Understand LLM application performance and ensure real-world expectations are met\n","\n","### Two Evaluation Approaches\n","\n","**1. End-User Feedback**:\n","- Collect user feedback\n","- Assess application usefulness\n","\n","**2. Ground Truth Comparison**:\n","- Compare LLM predictions with expected responses\n","- Gauge accuracy and relevance\n","\n","## Key Metrics\n","\n","### Groundedness\n","**Definition**: Measures alignment of output with input source or database\n","**Purpose**: Ensures responses are based on provided data\n","\n","### Relevance\n","**Definition**: Assesses how pertinent output is to given input\n","**Purpose**: Validates response appropriateness\n","\n","### Coherence\n","**Definition**: Evaluates logical flow and readability of text\n","**Purpose**: Ensures responses make sense and flow naturally\n","\n","### Fluency\n","**Definition**: Assesses grammatical and linguistic accuracy\n","**Purpose**: Validates language quality\n","\n","### Similarity\n","**Definition**: Quantifies contextual and semantic match between output and ground truth\n","**Purpose**: Measures how close responses are to expected answers\n","\n","## Quality Assurance Strategy\n","\n","### Monitoring Purpose\n","- Ensure accurate and effective interactions\n","- Identify when improvements are needed\n","- Maintain reliability of LLM applications\n","\n","### Iterative Improvement\n","When performance doesn't meet expectations → return to experimentation phase to improve flow\n","\n","## Key Takeaway\n","Variants allow testing different prompt versions in LLM tools. Deploy optimized flows to online endpoints for real-time API access. Monitor five key metrics (groundedness, relevance, coherence, fluency, similarity) to ensure quality and identify when flow improvements are necessary.\n"],"metadata":{"id":"Dy7e70ZpF1Fu"}},{"cell_type":"markdown","source":["# **Quiz**\n","---\n","\n","## Question 1: Secure Model Access\n","**Question**: A flow uses an LLM tool to generate text with a GPT-3.5 model. What do you need to create to ensure prompt flow can securely call the deployed model from Azure OpenAI?\n","\n","**Correct Answer**: Connections\n","\n","**Explanation**: Connections securely store credentials and endpoints for external services like Azure OpenAI, enabling secure communication.\n","\n","**Wrong Answers**:\n","- ❌ Runtimes: Provide compute resources, not authentication\n","- ❌ Tools: Execute tasks within flows, don't handle authentication\n","\n","## Question 2: Flow Integration\n","**Question**: You want to integrate your flow with an online website. What do you need to do to easily integrate your flow?\n","\n","**Correct Answer**: Deploy your flow to an endpoint\n","\n","**Explanation**: Deploying to an online endpoint generates a URL and key for API access from any application.\n","\n","**Wrong Answers**:\n","- ❌ Create a custom environment: Manages packages/libraries, not integration\n","- ❌ Create a runtime: Provides compute resources, not external access\n","\n","## Question 3: Underperformance Response\n","**Question**: After deployment, you notice that your flow is underperforming. Which stage in the development lifecycle should you revert back to?\n","\n","**Correct Answer**: Experimentation\n","\n","**Explanation**: Experimentation is the iterative development stage where you modify and improve flows.\n","\n","**Wrong Answers**:\n","- ❌ Evaluation and refinement: For testing with larger datasets, not initial improvements\n","- ❌ Production: Current stage, not where you fix issues\n","\n","## Key Patterns\n","\n","**Connections** = Secure external service access\n","**Endpoints** = Integration with applications\n","**Experimentation** = Flow improvement and iteration\n","\n","## Quick Reference\n","\n","| Need | Solution |\n","|------|----------|\n","| Secure API access | Connections |\n","| Application integration | Deploy to endpoint |\n","| Fix performance issues | Return to Experimentation |"],"metadata":{"id":"t_5UOvi0Up_O"}}]}