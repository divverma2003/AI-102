{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPAq418ua0/JTHDzkqViMoP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Introduction**\n","\n","---\n","\n","## Groundedness Definition\n","**Groundedness**: Whether a response is rooted, connected, or anchored in reality or specific context; based on factual information rather than invented content.\n","\n","## Ungrounded Prompts and Responses\n","\n","### Characteristics\n","- Model uses only training data (large volume of uncontextualized text)\n","- Responses are grammatically coherent and logical\n","- **Problem**: Uncontextualized, potentially inaccurate, may include invented information\n","\n","### Example Issue\n","Question: \"Which product should I use to do X?\"\n","**Risk**: Response may include details of fictional products\n","\n","## Grounded Prompts and Responses\n","\n","### Approach\n","Use a data source to ground the prompt with relevant, factual context before submitting to language model\n","\n","### Process\n","1. Retrieve relevant data from data source\n","2. Include grounding data with prompt\n","3. Language model generates contextualized, relevant, and accurate response\n","\n","### Data Source Examples\n","- Product catalog databases\n","- Corporate documentation\n","- Knowledge bases\n","- Real-time data repositories\n","\n","### Benefits\n","- Responses based on actual facts\n","- Contextually relevant information\n","- Accurate details from verified sources\n","- Reduced hallucination and invented content\n","\n","## Application\n","Build chat-based language model applications (agents) that are grounded using your own data to ensure accurate, factual responses.\n","\n","## Key Takeaway\n","Grounding uses external data sources to provide factual context for prompts, resulting in accurate, contextualized responses instead of potentially invented information from training data alone."],"metadata":{"id":"xan2DHz4WqDO"}},{"cell_type":"markdown","source":["# **Grounding**\n","\n","---\n","\n","## Groundedness Definition\n","**Groundedness**: Whether a response is rooted, connected, or anchored in reality or specific context; based on factual information rather than invented content.\n","\n","## Ungrounded Prompts and Responses\n","\n","### Characteristics\n","- Model uses only training data (large volume of uncontextualized text)\n","- Responses are grammatically coherent and logical\n","- **Problem**: Uncontextualized, potentially inaccurate, may include invented information\n","\n","### Example Issue\n","Question: \"Which product should I use to do X?\"\n","**Risk**: Response may include details of fictional products\n","\n","## Grounded Prompts and Responses\n","\n","### Approach\n","Use a data source to ground the prompt with relevant, factual context before submitting to language model\n","\n","### Process\n","1. Retrieve relevant data from data source\n","2. Include grounding data with prompt\n","3. Language model generates contextualized, relevant, and accurate response\n","\n","### Data Source Examples\n","- Product catalog databases\n","- Corporate documentation\n","- Knowledge bases\n","- Real-time data repositories\n","\n","### Benefits\n","- Responses based on actual facts\n","- Contextually relevant information\n","- Accurate details from verified sources\n","- Reduced hallucination and invented content\n","\n","## Application\n","Build chat-based language model applications (agents) that are grounded using your own data to ensure accurate, factual responses.\n","\n","## Key Takeaway\n","Grounding uses external data sources to provide factual context for prompts, resulting in accurate, contextualized responses instead of potentially invented information from training data alone."],"metadata":{"id":"yOHT9f-VY4ZM"}},{"cell_type":"markdown","source":["# **Make your data searchable**\n","---\n","## Azure AI Search Integration\n","**Purpose**: Retrieve relevant context for chat flows in Azure AI Foundry\n","**Function**: Acts as retriever in language model applications built with prompt flow\n","\n","## Vector Embeddings\n","\n","### Definition\n","**Embedding**: Special data format represented as vector of floating-point numbers; enables semantic similarity calculation\n","\n","### Example\n","Two semantically related documents:\n","- \"The children played joyfully in the park.\"\n","- \"Kids happily ran around the playground.\"\n","\n","**Result**: Vector embeddings capture semantic relationship despite different words\n","\n","### Cosine Similarity\n","**Method**: Calculate distance between vectors by measuring angle between them\n","**Purpose**: Compute semantic similarity between documents and queries\n","\n","### Benefits\n","- Extract relevant context across different formats (text, images)\n","- Work across multiple languages\n","- Find semantically similar content, not just keyword matches\n","\n","## Creating Search Indexes\n","\n","### Search Index Purpose\n","Describes how content is organized to make it searchable (like library catalog for books)\n","\n","### Index Creation in Azure AI Foundry\n","1. Add data to Azure AI Foundry\n","2. Use Azure AI Search to create index using embedding model\n","3. Index stored in Azure AI Search, queried by Azure AI Foundry in chat flows\n","\n","### Embedding Models\n","Use Azure OpenAI embedding models available in Azure AI Foundry to create embeddings for vector search\n","\n","## Search Techniques\n","\n","### Keyword Search\n","**Method**: Identifies documents based on specific keywords or exact terms\n","**Use case**: Precise matches when exact terminology is known\n","\n","### Semantic Search\n","**Method**: Understands query meaning, matches semantically related content\n","**Advantage**: Goes beyond exact keyword matches using semantic models\n","\n","### Vector Search\n","**Method**: Uses mathematical representations (vectors) to find similar content based on semantic meaning\n","**Advantage**: Most advanced technique, captures contextual relationships\n","\n","### Hybrid Search ⭐ (Recommended for Generative AI)\n","**Method**: Combines keyword, vector, and optionally semantic ranking\n","**Execution**: Queries run in parallel, results unified in single set\n","**Advantage**: Most accurate results for generative AI applications\n","\n","## Hybrid Search Details\n","\n","### How It Works\n","- **Single query request** with both full text and vector parameters\n","- **Parallel execution** of keyword and vector searches\n","- **Reciprocal Rank Fusion (RRF)** merges results into unified ranked output\n","\n","### Key Components\n","1. **Full text search**: Uses BM25 ranking for keyword matches\n","2. **Vector search**: Uses HNSW or eKNN algorithms for similarity\n","3. **RRF algorithm**: Merges and ranks unified results\n","4. **Optional semantic ranking**: Applies machine reading comprehension for relevance\n","\n","### Query Structure Elements\n","- **search**: Full text query parameter\n","- **vectorQueries**: Multiple vector queries targeting vector fields\n","- **select**: Fields to return in results\n","- **filter**: Include/exclude criteria (e.g., geospatial, property filters)\n","- **facets**: Compute facet buckets over results\n","- **queryType=semantic**: Invoke semantic ranker (optional)\n","\n","### Advantages\n","**Precision + Recall**:\n","- Keyword search provides precision with exact matches\n","- Vector search provides recall with conceptual similarity\n","- Combines strengths of both approaches\n","\n","**Best Performance Scenarios**:\n","- Product codes and IDs\n","- Specialized jargon\n","- Dates and names\n","- Conceptual similarity searches\n","\n","**Optimal for Generative AI**: Benchmark testing shows hybrid + semantic ranking offers significant benefits for search relevance and grounding data quality\n","\n","### Filter and Facet Support\n","- Filters apply to geospatial search, include/exclude criteria\n","- Can be applied pre-filter or post-filter\n","- Facets work over hybrid query results\n","- Independent of inverted and vector indexes\n","\n","### Important Notes\n","- No explicit `orderby` in hybrid queries (overrides relevance ranking)\n","- Set `k` to 50 when using semantic ranker to maximize inputs\n","- Multi-lingual content searchable without language analyzers\n","\n","## Key Takeaway\n","Azure AI Search with vector embeddings enables semantic search across data. Hybrid search (combining keyword, vector, and semantic ranking) provides the most accurate results for generative AI applications by balancing precision and conceptual similarity."],"metadata":{"id":"CbglKSSWaa7Z"}},{"cell_type":"markdown","source":["# **Create RAG-based client application**\n","\n","---\n","\n","## Overview\n","Use Azure AI Search index with OpenAI models by extending requests with index connection details through Azure OpenAI SDK.\n","\n","## Keyword-Based RAG Implementation\n","\n","### Basic Structure\n","```python\n","from openai import AzureOpenAI\n","\n","# Initialize OpenAI client\n","chat_client = AzureOpenAI(\n","    api_version = \"2024-12-01-preview\",\n","    azure_endpoint = open_ai_endpoint,\n","    api_key = open_ai_key\n",")\n","\n","# Create prompt with system and user messages\n","prompt = [\n","    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n","    {\"role\": \"user\", \"content\": input_text}\n","]\n","\n","# RAG parameters with Azure AI Search connection\n","rag_params = {\n","    \"data_sources\": [{\n","        \"type\": \"azure_search\",\n","        \"parameters\": {\n","            \"endpoint\": search_url,\n","            \"index_name\": \"index_name\",\n","            \"authentication\": {\n","                \"type\": \"api_key\",\n","                \"key\": search_key,\n","            }\n","        }\n","    }],\n","}\n","\n","# Submit prompt with index information\n","response = chat_client.chat.completions.create(\n","    model=\"<model_deployment_name>\",\n","    messages=prompt,\n","    extra_body=rag_params\n",")\n","```\n","\n","### Keyword-Based Query Characteristics\n","- Query consists of text from user prompt\n","- Matched to text in indexed documents\n","- Searches for literal text matches\n","\n","## Vector-Based RAG Implementation\n","\n","### Modified RAG Parameters\n","```python\n","rag_params = {\n","    \"data_sources\": [{\n","        \"type\": \"azure_search\",\n","        \"parameters\": {\n","            \"endpoint\": search_url,\n","            \"index_name\": \"index_name\",\n","            \"authentication\": {\n","                \"type\": \"api_key\",\n","                \"key\": search_key,\n","            },\n","            # Vector-based query configuration\n","            \"query_type\": \"vector\",\n","            \"embedding_dependency\": {\n","                \"type\": \"deployment_name\",\n","                \"deployment_name\": \"<embedding_model_deployment_name>\",\n","            },\n","        }\n","    }],\n","}\n","```\n","\n","### Vector-Based Query Characteristics\n","- Uses numeric vectors to represent text tokens\n","- Query text is vectorized using embedding model\n","- Enables matching based on semantic similarity\n","- Captures both semantic and literal matches\n","- Requires index that supports vector search\n","\n","## Key Components\n","\n","### Azure OpenAI Client\n","- API version: \"2024-12-01-preview\" (or current version)\n","- Requires endpoint and API key\n","- Handles chat completions with RAG\n","\n","### Prompt Structure\n","- System message: Defines AI assistant behavior\n","- User message: Contains user input/question\n","- Array format for conversation history\n","\n","### RAG Parameters (`extra_body`)\n","- Data source type: \"azure_search\"\n","- Connection parameters: endpoint, index name, authentication\n","- Query type: keyword (default) or vector\n","- Embedding dependency: for vector-based queries\n","\n","### Response Handling\n","- Response object contains choices\n","- Extract content: `response.choices[0].message.content`\n","- Content is contextualized based on indexed data\n","\n","## Comparison: Keyword vs Vector\n","\n","| Aspect | Keyword-Based | Vector-Based |\n","|--------|--------------|--------------|\n","| **Query Method** | Text matching | Semantic similarity |\n","| **Match Type** | Literal text | Semantic + literal |\n","| **Configuration** | Default | Requires `query_type: vector` |\n","| **Embedding Model** | Not required | Required in parameters |\n","| **Index Support** | Standard index | Vector-enabled index |\n","\n","## Implementation Requirements\n","\n","### Prerequisites\n","- Azure OpenAI deployment\n","- Azure AI Search index\n","- API keys for both services\n","- Embedding model deployment (for vector search)\n","\n","### Authentication\n","- API key-based authentication shown\n","- Both OpenAI and Search services require keys\n","- Keys stored securely, passed in parameters\n","\n","## Key Takeaway\n","RAG implementation extends Azure OpenAI requests with Azure AI Search index details via `extra_body` parameter. Keyword-based queries match literal text, while vector-based queries (requiring embedding model) enable semantic similarity matching for more accurate contextualized responses."],"metadata":{"id":"NMjNRSNNag-g"}},{"cell_type":"markdown","source":["# **Implement RAG in a prompt flow**\n","\n","---\n","\n","## Prompt Flow Overview\n","**Definition**: Development framework for defining flows that orchestrate interactions with LLMs\n","\n","**Structure**: Inputs → Connected Tools → Outputs\n","\n","## Flow Components\n","\n","### Inputs\n","- User question or prompt\n","- Chat history (for iterative conversations)\n","\n","### Tools (Operations)\n","- Run custom Python code\n","- Look up data values in an index\n","- Create prompt variants\n","- Submit prompts to LLM\n","\n","### Outputs\n","- Generated results from LLM\n","\n","## RAG Pattern in Prompt Flow\n","\n","### Key Component: Index Lookup Tool\n","**Purpose**: Retrieve data from index to augment prompts sent to LLM\n","\n","## Multi-Round Q&A Sample Flow\n","\n","### Flow Steps (in order)\n","\n","**1. Modify Query with History**\n","- **Tool**: LLM node\n","- **Purpose**: Takes chat history + user's last question → generates new question with all necessary info\n","- **Result**: More succinct input for rest of flow\n","\n","**2. Look Up Relevant Information**\n","- **Tool**: Index Lookup tool\n","- **Purpose**: Query Azure AI Search index to find relevant information\n","- **Result**: Retrieved context from data source\n","\n","**3. Generate Prompt Context**\n","- **Tool**: Python node\n","- **Purpose**: Parse Index Lookup output into suitable format\n","- **Process**: Iterate over top n retrieved documents, combine contents and sources into one document string\n","- **Result**: Formatted string for prompt\n","\n","**4. Define Prompt Variants**\n","- **Tool**: Prompt variants\n","- **Purpose**: Represent different prompt contents with varying system messages\n","- **Goal**: Instruct chatbot to use context and be factual (improve groundedness)\n","- **Result**: Multiple prompt versions to compare\n","\n","**5. Chat with Context**\n","- **Tool**: LLM node\n","- **Purpose**: Send prompt to language model with retrieved context\n","- **Result**: Natural language response (also flow output)\n","\n","### Example Flow\n","``INPUTS (question, chat_history)\n","    ↓\n","MODIFY_QUERY_WITH_HISTORY (LLM node)\n","    ↓\n","LOOKUP (Index Lookup tool)\n","    ↓\n","GENERATE_PROMPT_CONTEXT (Python node)\n","    ↓\n","PROMPT_VARIANTS (Prompt tool)\n","    ↓\n","CHAT_WITH_CONTEXT (LLM node)\n","    ↓\n","OUTPUTS (response)``\n","### Deployment\n","After configuration → deploy flow → integrate with application for agentic experience\n","\n","## Index Lookup Tool Details\n","\n","### Supported Index Types\n","- Azure AI Search\n","- FAISS\n","- Pinecone\n","\n","### Input Parameters\n","\n","| Parameter | Type | Description | Required |\n","|-----------|------|-------------|----------|\n","| **mlindex_content** | string | Type of Index to be used | Yes |\n","| **queries** | string, Union[string, List[String]] | Text to be queried | Yes |\n","| **query_type** | string | Type of query (Keyword, Semantic, Hybrid, Vector) | Yes |\n","| **top_k** | integer | Count of top-scored entities to return (default: 3) | No |\n","\n","### Query Types\n","- **Keyword**: Literal text matches\n","- **Semantic**: Meaning-based matches\n","- **Hybrid**: Combines multiple approaches\n","- **Vector**: Semantic similarity using embeddings\n","\n","### Output Format\n","Returns JSON with top-k scored entities containing:\n","\n","| Field | Type | Description |\n","|-------|------|-------------|\n","| **metadata** | dict | Customized key-value pairs (page_number, source, stats) |\n","| **page_content** | string | Content of vector chunk used in lookup |\n","| **score** | float | Relevance score (L2 distance for FAISS, cosine similarity for Azure AI Search) |\n","\n","### Output Structure Example\n","```json\n","[{\n","  \"metadata\": {\n","    \"page_number\": 44,\n","    \"source\": {\"filename\": \"file.pdf\", \"url\": \"...\"},\n","    \"stats\": {\"chars\": 4385, \"lines\": 41, \"tiktokens\": 891}\n","  },\n","  \"page_content\": \"vector chunk\",\n","  \"score\": 0.0213\n","}]\n","```\n","\n","### Configuration Requirements\n","- **mlindex_content**: Index connection details (embeddings config, index settings)\n","- **Vector input**: Generated by LLM tool for embedding-based queries\n","- **Field mapping**: Content, embedding, and metadata fields\n","\n","### Legacy Tool Migration\n","Index Lookup tool replaces three deprecated tools:\n","- Vector Index Lookup tool\n","- Vector DB Lookup tool\n","- FAISS Index Lookup tool\n","\n","## Key Takeaway\n","RAG in Prompt Flow uses Index Lookup tool to retrieve relevant context from indexed data, which is then formatted and used to augment prompts sent to LLMs. The Multi-Round Q&A sample provides a complete flow: modify query → lookup → generate context → create variants → chat with context."],"metadata":{"id":"4elG2w_CeHnQ"}},{"cell_type":"markdown","source":["# **Quiz**\n","---\n","\n","## Question 1: Groundedness Definition\n","**Question**: What does groundedness refer to in the context of generative AI?\n","\n","**Correct Answer**: Using data to contextualize prompts and ensure relevant responses\n","\n","**Explanation**: Groundedness means anchoring responses in factual, relevant data rather than relying solely on training data.\n","\n","**Wrong Answers**:\n","- ❌ The use of a locally deployed language model: Deployment location doesn't affect groundedness\n","- ❌ Using the lowest possible number of tokens in a prompt: Token count relates to efficiency, not factual accuracy\n","\n","## Question 2: Grounding Pattern\n","**Question**: What pattern can you use to ground prompts?\n","\n","**Correct Answer**: Retrieval Augmented Generation (RAG)\n","\n","**Explanation**: RAG retrieves relevant data from external sources to provide factual context for prompts.\n","\n","**Wrong Answers**:\n","- ❌ Metadata Optimized Prompt (MOP): Not a real pattern\n","- ❌ Data Understanding Support Text (DUST): Not a real pattern\n","\n","## Question 3: RAG Implementation in Client Apps\n","**Question**: How can you use the RAG pattern in a client app that uses the Azure OpenAI SDK?\n","\n","**Correct Answer**: Add index connection details to the OpenAI ChatClient configuration\n","\n","**Explanation**: Use `extra_body` parameter with `data_sources` containing Azure AI Search index connection details.\n","\n","**Wrong Answers**:\n","- ❌ Add text files containing the grounding data to the app folder: Data should be in searchable index, not local files\n","- ❌ Azure AI Foundry automatically grounds all prompts using Bing Search: Grounding requires explicit configuration\n","\n","## Key Patterns\n","\n","**Groundedness** = Using external data to contextualize prompts\n","**RAG Pattern** = Retrieval Augmented Generation for grounding\n","**Implementation** = Add index connection details via `extra_body` parameter\n","\n","## Quick Reference\n","\n","| Concept | Implementation |\n","|---------|----------------|\n","| Ground prompts | Use RAG pattern |\n","| RAG in Azure OpenAI SDK | Add index details to `extra_body` |\n","| Data source | Azure AI Search index |"],"metadata":{"id":"C94YCAG8fkRq"}},{"cell_type":"markdown","source":["# **Code Exercise**\n","---\n","\n","## Required Model Deployments\n","\n","### Two Models Needed\n","1. **Embedding Model**: text-embedding-ada-002\n","   - Purpose: Vectorize text data for indexing\n","   - Deployment type: Global Standard\n","   - TPM: 50K\n","\n","2. **Generation Model**: gpt-4o\n","   - Purpose: Generate natural language responses\n","   - Deployment type: Global Standard\n","   - TPM: 50K\n","\n","## Data Setup\n","\n","### Upload Data\n","1. Add data source to project (PDF brochures)\n","2. Upload folder with documents\n","3. Name data source (e.g., \"brochures\")\n","\n","## Index Creation\n","\n","### Index Configuration\n","**Source**: Data in Azure AI Foundry (select data source)\n","\n","**Azure AI Search Settings**:\n","- Create new Azure AI Search resource\n","- Same location as AI hub\n","- Pricing tier: Basic\n","\n","**Index Name**: brochures-index\n","\n","**Vector Settings**:\n","- Add vector search to resource\n","- Select Azure OpenAI connection\n","- Embedding model: text-embedding-ada-002\n","- Select embedding model deployment\n","\n","### Index Creation Jobs\n","1. Crack, chunk, and embed text tokens\n","2. Create Azure AI Search index\n","3. Register index asset\n","\n","## Testing in Playground\n","\n","### Without Index\n","**Prompt**: \"Where can I stay in New York?\"\n","**Result**: Generic answer without custom data\n","\n","### With Index\n","1. Add project index to Setup pane\n","2. Select hybrid (vector + keyword) search type\n","3. Submit same prompt\n","**Result**: Response based on indexed data\n","\n","## RAG Client Application Code\n","\n","### Essential Components\n","\n","```python\n","from openai import AzureOpenAI\n","\n","# Create Azure OpenAI client\n","chat_client = AzureOpenAI(\n","    api_version = \"2024-12-01-preview\",\n","    azure_endpoint = openai_endpoint,\n","    api_key = openai_api_key\n",")\n","\n","# System message for chat solution\n","system_message = \"You are a helpful travel assistant.\"\n","\n","# Create prompt with messages\n","messages = [\n","    {\"role\": \"system\", \"content\": system_message},\n","    {\"role\": \"user\", \"content\": user_input}\n","]\n","\n","# RAG configuration with search index\n","rag_params = {\n","    \"data_sources\": [\n","        {\n","            \"type\": \"azure_search\",\n","            \"parameters\": {\n","                \"endpoint\": search_endpoint,\n","                \"index_name\": index_name,\n","                \"authentication\": {\n","                    \"type\": \"api_key\",\n","                    \"key\": search_api_key,\n","                },\n","                # Vector-based query configuration\n","                \"query_type\": \"vector\",\n","                \"embedding_dependency\": {\n","                    \"type\": \"deployment_name\",\n","                    \"deployment_name\": embedding_model_deployment,\n","                },\n","            }\n","        }\n","    ],\n","}\n","\n","# Submit prompt with RAG parameters\n","response = chat_client.chat.completions.create(\n","    model=chat_model_deployment,\n","    messages=messages,\n","    extra_body=rag_params\n",")\n","\n","# Get response\n","answer = response.choices[0].message.content\n","print(answer)\n","\n","# Add to chat history for multi-turn conversation\n","messages.append({\"role\": \"assistant\", \"content\": answer})\n","```\n","\n","## Key Implementation Details\n","\n","### Vectorization Process\n","- Query submitted as text to search index\n","- Embedding model vectorizes query text\n","- Vector-based search finds semantically similar content\n","- More efficient than keyword-only search\n","\n","### Response Grounding\n","- Search index queried based on user prompt\n","- Relevant text found in indexed documents\n","- Context added to prompt before LLM generation\n","- Response includes source references\n","\n","### Multi-Turn Conversations\n","- Append assistant responses to message history\n","- Maintain conversation context\n","- Enable follow-up questions\n","\n","## Search Type Options\n","\n","### Keyword Search\n","- Text-based matching\n","- Exact or fuzzy text matches\n","\n","### Vector Search\n","- Semantic similarity matching\n","- Uses embeddings for comparison\n","\n","### Hybrid Search (Recommended)\n","- Combines vector + keyword search\n","- Best accuracy for RAG applications\n","\n","## Configuration Requirements\n","\n","### Essential Parameters\n","- **openai_endpoint**: Azure OpenAI endpoint\n","- **openai_api_key**: API key for authentication\n","- **chat_model_deployment**: GPT model deployment name\n","- **embedding_model_deployment**: Embedding model deployment name\n","- **search_endpoint**: Azure AI Search URL\n","- **search_api_key**: Search API key\n","- **index_name**: Name of created index\n","\n","## Testing Workflow\n","\n","1. **Test without index**: Verify generic responses\n","2. **Add index**: Configure in playground\n","3. **Test with index**: Verify grounded responses\n","4. **Implement in code**: Use SDK for application\n","5. **Test multi-turn**: Verify conversation context\n","\n","## Key Takeaway\n","RAG implementation requires deploying embedding and generation models, creating a vector index with Azure AI Search, and using the Azure OpenAI SDK with `extra_body` parameter containing search index connection details and embedding model configuration for vectorized queries."],"metadata":{"id":"e8OyciUt0W56"}}]}