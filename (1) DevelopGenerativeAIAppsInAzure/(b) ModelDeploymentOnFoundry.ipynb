{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPwar5E0H3Cs14S6RbTubhM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Introduction**\n","---\n","## Generative AI Development Process\n","\n","### Foundation Models\n","**Definition**: State-of-the-art language models designed to understand, generate, and interact with natural language (e.g., GPT family)\n","\n","**Development Workflow**:\n","1. **Explore and compare** available foundation models\n","2. **Select** model that best suits application needs\n","3. **Deploy** model to an endpoint\n","4. **Consume** via client application or AI agent\n","\n","## Common Use Cases for Language Models\n","\n","### Text Processing\n","- **Speech-to-text and text-to-speech conversion**: Generate subtitles for videos\n","- **Machine translation**: Translate text between languages (e.g., English to Japanese)\n","- **Text classification**: Label content (e.g., spam detection in emails)\n","- **Entity extraction**: Extract keywords, names, or specific information from documents\n","- **Text summarization**: Generate concise summaries from lengthy documents\n","\n","### Interactive Applications\n","- **Question answering**: Provide responses to factual questions (e.g., \"What is the capital of France?\")\n","- **Reasoning**: Solve mathematical problems and logical challenges\n","\n","## Transformer Architecture: The Foundation of Modern AI\n","\n","### Historical Context\n","**Breakthrough Paper**: \"Attention is All You Need\" by Vaswani, et al. (2017)\n","**Impact**: Enabled the emergence of foundation models through architectural innovations\n","\n","### Key Innovations\n","\n","#### 1. Attention Mechanism\n","**Traditional Approach**: Sequential word processing (one word at a time)\n","**Transformer Innovation**: Parallel processing of all words independently using attention\n","**Benefit**: Dramatically improved processing efficiency and contextual understanding\n","\n","#### 2. Positional Encoding\n","**Purpose**: Include information about word position within sentences\n","**Function**: Maintains semantic relationships while understanding word order\n","**Result**: Better comprehension of sentence structure and meaning\n","\n","## Key Technical Concepts\n","\n","### Attention Mechanism\n","- Allows models to focus on relevant parts of input when generating output\n","- Enables parallel processing instead of sequential processing\n","- Improves model's ability to understand context and relationships\n","\n","### Positional Encoding\n","- Preserves word order information in parallel processing\n","- Combines with semantic similarity for comprehensive understanding\n","- Essential for maintaining sentence structure meaning\n","\n","## Foundation Model Selection Criteria\n","\n","When choosing a foundation model, consider:\n","- **Task requirements**: Specific use case needs\n","- **Performance metrics**: Accuracy for intended applications\n","- **Resource constraints**: Computational and cost considerations\n","- **Integration requirements**: Compatibility with deployment environment\n","\n","## Deployment Considerations\n","\n","### Endpoint Deployment\n","- Models are deployed to accessible endpoints\n","- Endpoints enable consumption by client applications\n","- Support for both direct application integration and AI agent workflows\n","\n","### Client Integration Options\n","- **Direct API calls**: Applications call model endpoints directly\n","- **AI Agent integration**: Models power intelligent agent systems\n","- **SDK integration**: Use Azure AI SDKs for streamlined development\n","\n","## Key Takeaway\n","The Transformer architecture revolutionized NLP by introducing parallel processing with attention mechanisms and positional encoding, enabling the development of powerful foundation models that serve as the basis for modern generative AI applications."],"metadata":{"id":"y1cfV2BAZe36"}},{"cell_type":"markdown","source":["# **Model Catalog and Selection**\n","\n","---\n","\n","## Azure AI Foundry Model Catalog\n","**Purpose**: Central repository for browsing and finding the right language model for generative AI use cases\n","\n","## Three-Question Framework for Model Selection\n","\n","### 1. Can AI solve my use case?\n","### 2. How do I select the best model for my use case?\n","### 3. Can I scale for real-world workloads?\n","\n","## Model Discovery Sources\n","\n","### Model Catalogs\n","- **Hugging Face**: Vast catalog of open-source models across various domains\n","- **GitHub**: Access to diverse models via GitHub Marketplace and GitHub Copilot\n","- **Azure AI Foundry**: Comprehensive catalog with robust deployment tools (recommended for prototyping)\n","\n","## Model Types and Categories\n","\n","### Large vs. Small Language Models\n","\n","**Large Language Models (LLMs)**:\n","- Examples: GPT-4, Mistral Large, Llama3 70B, Llama 405B, Command R+\n","- Best for: Deep reasoning, complex content generation, extensive context understanding\n","- Trade-offs: Higher cost, more computational resources\n","\n","**Small Language Models (SLMs)**:\n","- Examples: Phi3, Mistral OSS models, Llama3 8B\n","- Best for: Common NLP tasks, edge devices, cost-sensitive applications\n","- Benefits: Efficient, cost-effective, faster processing\n","\n","### Model Categories by Functionality\n","\n","**Chat Completion Models**:\n","- Examples: GPT-4, Mistral Large\n","- Purpose: Generate coherent, contextually appropriate text responses\n","\n","**Reasoning Models**:\n","- Examples: DeepSeek-R1, o1\n","- Purpose: Complex tasks requiring math, coding, science, strategy, logistics\n","\n","**Multi-Modal Models**:\n","- Examples: GPT-4o, Phi3-vision\n","- Capabilities: Process images, audio, and text\n","- Use cases: Computer vision, document analysis, digital tutoring\n","\n","**Image Generation Models**:\n","- Examples: DALL·E 3, Stability AI\n","- Purpose: Create realistic visuals from text prompts\n","- Applications: Marketing materials, illustrations, digital art\n","\n","**Embedding Models**:\n","- Examples: Ada, Cohere\n","- Purpose: Convert text to numerical representations\n","- Applications: RAG scenarios, search relevance, recommendation engines\n","\n","**Function Calling & JSON Models**:\n","- Capabilities: Work with structured data, API calls, database queries\n","- Use cases: Tool integration, automated data processing\n","\n","### Specialized Models\n","\n","**Regional/Language-Specific**:\n","- **Core42 JAIS**: Arabic language LLM\n","- **Mistral Large**: Strong focus on European languages\n","\n","**Domain-Specific**:\n","- **Nixtla TimeGEN-1**: Time-series forecasting for financial predictions, supply chain optimization\n","\n","### Open vs. Proprietary Models\n","\n","**Proprietary Models**:\n","- Examples: OpenAI GPT-4, Mistral Large, Cohere Command R+\n","- Benefits: Cutting-edge performance, enterprise security, high accuracy\n","- Best for: Enterprise use requiring support and compliance\n","\n","**Open-Source Models**:\n","- Sources: Hugging Face, Meta, Databricks, Snowflake, Nvidia\n","- Benefits: Flexibility, cost-efficiency, customization control\n","- Best for: Fine-tuning, local deployment, development control\n","\n","## Model Selection Criteria\n","\n","### Four Key Characteristics\n","\n","**1. Task Type**:\n","- Text-only vs. multi-modal requirements\n","- Specific capabilities needed (reasoning, generation, analysis)\n","\n","**2. Precision**:\n","- Base model vs. fine-tuned model requirements\n","- Domain-specific accuracy needs\n","\n","**3. Openness**:\n","- Need for fine-tuning capabilities\n","- Customization requirements\n","\n","**4. Deployment**:\n","- Local vs. serverless vs. managed infrastructure\n","- Scalability and performance requirements\n","\n","## Model Evaluation Approaches\n","\n","### Benchmark Metrics\n","\n","**Accuracy**: Exact match with correct answers\n","**Coherence**: Smooth, natural flow of generated text\n","**Fluency**: Grammatical correctness and natural language usage\n","**Groundedness**: Alignment between generated answers and input data\n","**GPT Similarity**: Semantic similarity to ground truth\n","**Quality Index**: Comparative aggregate score (0-1 scale)\n","**Cost**: Price-per-token for cost-effectiveness analysis\n","\n","### Evaluation Methods\n","\n","**Manual Evaluations**:\n","- Quick quality assessment\n","- Subjective rating of model responses\n","- Good for initial exploration\n","\n","**Automated Evaluations**:\n","- Traditional ML metrics (precision, recall, F1 score)\n","- AI-assisted metrics\n","- Scalable and objective approach\n","- Based on ground truth data\n","\n","## Scaling for Real-World Workloads\n","\n","### Key Considerations\n","\n","**Model Deployment**:\n","- Optimal balance of performance and cost\n","- Infrastructure requirements\n","\n","**Model Monitoring and Optimization**:\n","- Performance tracking\n","- Continuous evaluation and improvement\n","\n","**Prompt Management**:\n","- Prompt orchestration and optimization\n","- Maximizing accuracy and relevance\n","\n","**Model Lifecycle (GenAIOps)**:\n","- Model updates and versioning\n","- Data and code management\n","- Continuous integration and deployment\n","\n","## Azure AI Foundry Enterprise Benefits\n","\n","**Data and Privacy**: Control over data handling and usage\n","**Security and Compliance**: Built-in security features\n","**Responsible AI and Content Safety**: Integrated evaluations and safety measures\n","\n","## Key Takeaway\n","Model selection should follow a structured approach considering task requirements, performance needs, deployment constraints, and scalability requirements. Azure AI Foundry provides comprehensive tools for discovery, evaluation, and deployment of appropriate models for specific use cases."],"metadata":{"id":"cp5bL8ladcVk"}},{"cell_type":"markdown","source":["# **AI-102 Study Notes: Model Deployment to Endpoints**\n","\n","---\n","\n","## Why Deploy a Model?\n","\n","### The Need for Deployment\n","**Purpose**: Enable applications to send input to models and receive processed output\n","\n","**Common Implementation**: Chat applications where:\n","1. User asks a question (input)\n","2. Model processes the question\n","3. Model generates appropriate response (output)\n","4. Response is visualized to the user\n","\n","### Endpoint Integration\n","**Endpoint Definition**: Specific URL where a deployed model or service can be accessed\n","\n","**Key Characteristics**:\n","- Each model deployment has its own unique endpoint\n","- Enables communication between applications and models through APIs\n","- Provides standardized access point for model integration\n","\n","## Model Integration Workflow\n","\n","### API Communication Process\n","1. **User Input**: User asks a question in the application\n","2. **API Request**: Application sends API request to the model endpoint\n","3. **Model Processing**: Endpoint specifies which model processes the request\n","4. **API Response**: Result is sent back to the application\n","5. **User Output**: Response is displayed to the user\n","\n","## Azure AI Foundry Deployment Options\n","\n","### 1. Standard Deployment\n","**Hosting**: Models hosted in the Azure AI Foundry project resource\n","**Supported Models**: Azure AI Foundry models (including Azure OpenAI models and Models-as-a-Service models)\n","**Billing**: Token-based billing\n","**Recommendation**: **Recommended for most scenarios**\n","\n","### 2. Serverless Compute\n","**Hosting**: Microsoft-managed dedicated serverless endpoints in Azure AI Foundry hub project\n","**Supported Models**: Foundry Models with pay-as-you-go billing\n","**Hosting Service**: AI Project resource in a hub\n","**Billing**: Token-based billing\n","**Benefits**: No infrastructure management required\n","\n","### 3. Managed Compute\n","**Hosting**: Managed virtual machine images in Azure AI Foundry hub project\n","**Supported Models**: Open and custom models\n","**Hosting Service**: AI Project resource in a hub\n","**Billing**: Compute-based billing (based on VM resources)\n","**Use Cases**: Custom models requiring specific compute configurations\n","\n","## Deployment Comparison Matrix\n","\n","| Deployment Type | Hosting Location | Supported Models | Billing Method | Best For |\n","|-----------------|------------------|------------------|----------------|----------|\n","| **Standard** | Azure AI Foundry project resource | Azure AI Foundry models, Azure OpenAI, MaaS models | Token-based | Most scenarios (recommended) |\n","| **Serverless** | Microsoft-managed serverless endpoints | Foundry Models (pay-as-you-go) | Token-based | Scalable, managed infrastructure |\n","| **Managed** | Managed VM images in hub project | Open and custom models | Compute-based | Custom models, specific compute needs |\n","\n","## Cost Considerations\n","\n","### Factors Affecting Cost\n","- **Model type**: Different models have different pricing structures\n","- **Deployment option**: Standard vs. serverless vs. managed compute\n","- **Usage patterns**: Token consumption or compute time\n","\n","### Billing Models\n","**Token-based Billing**:\n","- Pay per API call/token processed\n","- Common for Standard and Serverless deployments\n","- Scales with actual usage\n","\n","**Compute-based Billing**:\n","- Pay for underlying compute resources (VMs)\n","- Used with Managed Compute deployments\n","- Costs incurred whether model is actively used or not\n","\n","## Key Decision Factors\n","\n","### Choose Standard Deployment when:\n","- Working with Azure AI Foundry or Azure OpenAI models\n","- Need straightforward, recommended deployment approach\n","- Want token-based billing aligned with usage\n","\n","### Choose Serverless Compute when:\n","- Need Microsoft-managed infrastructure\n","- Want automatic scaling capabilities\n","- Working with supported Foundry Models\n","- Prefer minimal infrastructure management\n","\n","### Choose Managed Compute when:\n","- Deploying open-source or custom models\n","- Need specific compute configurations\n","- Require fine-grained control over underlying infrastructure\n","- Have predictable, consistent workloads that justify compute costs\n","\n","## API Integration Concepts\n","\n","### Endpoint Characteristics\n","- **Unique URLs**: Each deployment gets a distinct endpoint\n","- **API Access**: RESTful API interface for model communication\n","- **Security**: Authentication and authorization mechanisms\n","- **Scalability**: Handle multiple concurrent requests\n","\n","### Application Integration\n","- Use Azure AI SDKs for streamlined integration\n","- Implement proper error handling and retry logic\n","- Consider rate limiting and quota management\n","- Monitor usage and performance metrics\n","\n","## Key Takeaway\n","Standard deployment is recommended for most scenarios, providing token-based billing and hosting in Azure AI Foundry project resources. Choose deployment type based on model requirements, infrastructure preferences, and billing considerations."],"metadata":{"id":"REPmLvxOfQOJ"}},{"cell_type":"markdown","source":["# **Model Performance Optimization**\n","\n","---\n","\n","## Prompt Engineering Overview\n","**Definition**: Process of designing and optimizing prompts to improve model performance through relevant, specific, unambiguous, and well-structured questions.\n","\n","**Key Principle**: Quality of input questions directly influences quality of output responses.\n","\n","## Five Core Prompt Patterns\n","\n","### 1. Persona Pattern\n","**Purpose**: Make the model adopt a specific point of view or perspective\n","\n","**Implementation**: Use system prompts to define the persona without exposing instructions to end users\n","\n","**Example Applications**:\n","- Marketing professional for CRM insights\n","- Product manager for feature analysis\n","- Data analyst for technical reports\n","- Customer service expert for support scenarios\n","\n","**Benefits**: Provides tailored, context-driven responses aligned with specific expertise\n","\n","### 2. Question Refinement Pattern\n","**Purpose**: Ask the model to suggest better ways to phrase queries and provide additional context\n","\n","**Implementation**: Request clarifying questions to get more targeted answers\n","\n","**Example**: Instead of \"What should I cook?\" ask \"What should I cook? What other information do you need to help me plan a great meal?\"\n","\n","**Benefits**: Achieves better, more accurate answers in fewer interactions\n","\n","### 3. Format Template Pattern\n","**Purpose**: Generate output in specific, structured formats\n","\n","**Implementation**: Provide templates or structures in prompts, use one-shot or few-shot examples\n","\n","**Applications**:\n","- Sports reporting with specific headings and data breakdowns\n","- Email templates\n","- Code and script generation\n","- Proposals and summaries\n","\n","**Benefits**: Consistent and organized responses following predefined structures\n","\n","### 4. Reasoning Explanation Pattern\n","**Purpose**: Make the model explain its reasoning and thought process\n","\n","**Implementation**: Ask for step-by-step explanations and rationale behind answers\n","\n","**Technique**: Chain-of-thought prompting for step-by-step thinking\n","\n","**Applications**:\n","- Mathematical calculations\n","- Data analysis explanations\n","- Marketing strategy reasoning\n","- Technical troubleshooting\n","\n","**Benefits**: Transparency in decision-making and educational value\n","\n","### 5. Context Specification Pattern\n","**Purpose**: Focus the model on specific topics and ignore irrelevant information\n","\n","**Implementation**:\n","- Define what to include or exclude\n","- Connect to specific data sources\n","- Provide relevant background information\n","\n","**Applications**:\n","- Trip planning with specific interests\n","- Domain-specific analysis\n","- Targeted recommendations\n","\n","**Benefits**: More relevant and tailored responses\n","\n","## System Prompts vs User Prompts\n","\n","### System Prompts\n","**Purpose**: Set model behavior and guide responses without exposing instructions to end users\n","**Best Practice**: Use for persona assignment and behavioral guidelines\n","**Scope**: Applies to entire conversation context\n","\n","### User Prompts\n","**Purpose**: Specific questions or requests from the end user\n","**Integration**: Works with system prompt instructions\n","**Flexibility**: Can be modified per interaction\n","\n","## Advanced Optimization Strategies\n","\n","### When Prompt Engineering Isn't Sufficient\n","\n","Consider additional strategies when prompts don't provide adequate context or guidance:\n","\n","### Retrieval Augmented Generation (RAG)\n","**Purpose**: Provide grounding context from external data sources\n","\n","**Use Cases**:\n","- Domain-specific knowledge bases\n","- Recent information beyond training data\n","- Corporate policies and documentation\n","- Real-time data integration\n","\n","**Process**: Retrieve relevant context → Generate response based on retrieved data\n","\n","### Fine-Tuning\n","**Purpose**: Extend foundation model training with specific examples\n","\n","**Use Cases**:\n","- Consistent response format and style\n","- Domain-specific language patterns\n","- Specialized behavior requirements\n","\n","**Process**: Train base model on dataset of example prompts and responses\n","\n","## Optimization Strategy Selection\n","\n","### Decision Framework\n","\n","**Optimize for Context** (Use RAG):\n","- Model lacks contextual knowledge\n","- Need to maximize response accuracy\n","- Require current or domain-specific information\n","\n","**Optimize the Model** (Use Fine-tuning):\n","- Need consistent response format/style\n","- Require specialized behavior patterns\n","- Want to maximize consistency across interactions\n","\n","### Combined Approaches\n","**Flexibility**: Can combine multiple strategies\n","- Prompt engineering + RAG\n","- Prompt engineering + Fine-tuning\n","- All three approaches together\n","\n","## Cost and Complexity Considerations\n","\n","### Implementation Order\n","1. **Start with prompt engineering** (lowest cost/complexity)\n","2. **Add RAG if context is insufficient**\n","3. **Consider fine-tuning for consistency issues**\n","\n","### Trade-offs\n","- **Prompt Engineering**: Low cost, immediate implementation, limited by context window\n","- **RAG**: Moderate cost, requires data infrastructure, improves accuracy\n","- **Fine-tuning**: Higher cost, requires training data and compute, maximum customization\n","\n","## Best Practices\n","\n","### Prompt Design\n","- Be specific and unambiguous\n","- Provide clear instructions and examples\n","- Use appropriate personas for context\n","- Request explanations when transparency is needed\n","\n","### System Architecture\n","- Implement system prompts for consistent behavior\n","- Design templates for structured outputs\n","- Plan for context management and data integration\n","\n","### Performance Monitoring\n","- Test prompts with various inputs\n","- Monitor response quality and consistency\n","- Iterate on prompt design based on results\n","- Consider user feedback in optimization\n","\n","## Key Takeaway\n","Start optimization with prompt engineering techniques, then layer additional strategies (RAG, fine-tuning) based on specific requirements for context, consistency, and performance. The goal is to balance effectiveness with cost and complexity."],"metadata":{"id":"ae9djNGLg8FR"}},{"cell_type":"markdown","source":["# **Quiz**\n","\n","---\n","\n","### Question 1: Testing Deployed Models\n","**Question**: Where can you test a deployed model in the Azure AI Foundry portal?\n","\n","**Correct Answer**: Chat playground\n","\n","**Key Learning**:\n","- Chat playground is the primary testing environment in Azure AI Foundry portal\n","- Provides interactive interface for testing model responses\n","- Allows real-time experimentation with prompts and parameters\n","\n","**Incorrect Options**:\n","- Sandbox: Not the specific testing environment for deployed models\n","- Development toolbox: Not the correct testing interface\n","\n","### Question 2: Customizing Model Responses\n","**Question**: You want to specify the tone, format, and content for each interaction with your model in the playground. What should you use to customize the model response?\n","\n","**Correct Answer**: System message\n","\n","**Key Learning**:\n","- **System message** sets model behavior and personality for entire conversation\n","- Controls tone, format, and content guidelines\n","- Applied consistently across all user interactions\n","- Not exposed to end users (unlike user prompts)\n","\n","**Incorrect Options**:\n","- Benchmarks: Used for evaluating model performance, not customizing responses\n","- Grounding: Refers to providing context/data sources, not behavioral customization\n","\n","### Question 3: OpenAI Model Deployment\n","**Question**: What deployment option should you choose to host an OpenAI model in an Azure AI Foundry resource?\n","\n","**Correct Answer**: Standard deployment\n","\n","**Key Learning**:\n","- **Standard deployment** is recommended for most scenarios\n","- Specifically designed for Azure AI Foundry models (including OpenAI models)\n","- Uses token-based billing\n","- Hosted in Azure AI Foundry project resource\n","\n","**Incorrect Options**:\n","- Serverless compute: For Foundry Models with pay-as-you-go billing\n","- Managed compute: For open and custom models in VM images\n","\n","## Key Patterns for Exam Success\n","\n","### Testing and Development Workflow\n","1. **Deploy model** to endpoint\n","2. **Test in Chat playground**\n","3. **Customize with System message**\n","4. **Iterate and optimize** based on results\n","\n","### Deployment Decision Matrix\n","| Model Type | Recommended Deployment | Billing Model |\n","|------------|----------------------|---------------|\n","| **OpenAI Models** | Standard deployment | Token-based |\n","| **Azure AI Foundry Models** | Standard deployment | Token-based |\n","| **Open/Custom Models** | Managed compute | Compute-based |\n","| **Pay-as-you-go Models** | Serverless compute | Token-based |\n","\n","### System Message vs Other Customization Methods\n","\n","**System Message**:\n","- Sets consistent behavior across conversation\n","- Controls tone, format, content guidelines\n","- Hidden from end users\n","- Applied at conversation level\n","\n","**Benchmarks**:\n","- Performance evaluation metrics\n","- Not for response customization\n","- Used for model comparison\n","\n","**Grounding**:\n","- Provides external context/data\n","- Enhances accuracy with specific information\n","- Not for behavioral customization\n","\n","## Exam Strategy Insights\n","\n","### Pattern Recognition\n","- **Testing deployed models** → Chat playground\n","- **Customizing response behavior** → System message\n","- **OpenAI model hosting** → Standard deployment\n","\n","### Key Distinctions\n","- **Chat playground**: Interactive testing environment\n","- **System message**: Behavioral customization tool\n","- **Standard deployment**: Default choice for Azure AI Foundry and OpenAI models\n","\n","### Memory Aids\n","- **Standard = OpenAI**: Standard deployment for OpenAI models\n","- **System = Style**: System message for response style/format\n","- **Chat = Check**: Chat playground for checking deployed models\n","\n","## Critical Exam Points\n","\n","### Azure AI Foundry Portal Navigation\n","- Chat playground is the go-to testing interface\n","- System messages provide conversation-level customization\n","- Standard deployment is the default and recommended option\n","\n","### Model Customization Hierarchy\n","1. **System message**: Overall behavior and style\n","2. **User prompts**: Specific requests and questions\n","3. **Grounding/RAG**: External context and data\n","4. **Fine-tuning**: Model-level behavioral changes\n","\n","### Deployment Best Practices\n","- Choose Standard deployment for OpenAI models\n","- Use Chat playground for testing\n","- Implement System messages for consistent behavior\n","- Monitor and optimize based on playground results"],"metadata":{"id":"cTWfxJIrnl-j"}}]}