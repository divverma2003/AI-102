{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c480214",
   "metadata": {},
   "source": [
    "# Develop Generative AI Solutions in Azure\n",
    "\n",
    "## Create a Generative AI Chat Application\n",
    "\n",
    "**Purpose:** Build a simple Python-based chat application that connects to an Azure AI Foundry project and chats with a deployed language model using the Foundry SDK.\n",
    "\n",
    "**Estimated Time:** ~40 minutes\n",
    "**SDK Status:** Pre-release (behavior and APIs may change)\n",
    "\n",
    "**SDK Options (Exam Awareness):**\n",
    "\n",
    "* Azure AI Projects – Python\n",
    "* Azure AI Projects – .NET\n",
    "* Azure AI Projects – JavaScript\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Deploy a Model in a Foundry Project\n",
    "\n",
    "### Open Foundry Portal\n",
    "\n",
    "1. Navigate to **[https://ai.azure.com](https://ai.azure.com)**.\n",
    "2. Sign in with your **Azure credentials**.\n",
    "3. Close tips, quick starts, and the Help pane.\n",
    "4. Use the **Foundry logo** to return to the Home page if needed.\n",
    "\n",
    "---\n",
    "\n",
    "### Select and Deploy gpt-4o\n",
    "\n",
    "1. On the Home page, locate **Explore models and capabilities**.\n",
    "2. Search for **gpt-4o**.\n",
    "3. Open the model details page.\n",
    "4. Select **Use this model**.\n",
    "\n",
    "---\n",
    "\n",
    "### Create the Project\n",
    "\n",
    "When prompted:\n",
    "\n",
    "* Enter a valid **Project name**\n",
    "* Expand **Advanced options** → **Customize**\n",
    "\n",
    "Specify:\n",
    "\n",
    "* **Foundry resource:** Valid name\n",
    "* **Subscription:** Your Azure subscription\n",
    "* **Resource group:** Create or select\n",
    "* **Region:** Any AI Foundry–recommended region\n",
    "\n",
    "> Regional quotas apply. If quota is exceeded, you may be prompted to deploy the model in another region.\n",
    "\n",
    "Select **Create** and wait for the project and model deployment to complete.\n",
    "\n",
    "---\n",
    "\n",
    "### Important Quota Note\n",
    "\n",
    "If the model is deployed in a **different region** due to quota limitations:\n",
    "\n",
    "* You **cannot** use the default project endpoint\n",
    "* You **must** use the **model-specific Target URI** from **Models + Endpoints**\n",
    "\n",
    "---\n",
    "\n",
    "### Verify Deployment\n",
    "\n",
    "* The **Chat Playground** opens automatically\n",
    "* In the **Setup pane**, note the **deployment name** (usually `gpt-4o`)\n",
    "* Confirm via **Models + endpoints** if needed\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Prepare the Client Application Configuration\n",
    "\n",
    "### Get the Project Endpoint\n",
    "\n",
    "1. In Foundry portal, open the **Project Overview** page.\n",
    "2. In **Endpoints and keys**:\n",
    "\n",
    "   * Ensure **Foundry library** is selected\n",
    "   * Copy the **Foundry project endpoint**\n",
    "\n",
    "> You may also use the Azure OpenAI endpoint.\n",
    "\n",
    "---\n",
    "\n",
    "### Open Azure Cloud Shell\n",
    "\n",
    "1. Open a new tab and go to **[https://portal.azure.com](https://portal.azure.com)**.\n",
    "2. Sign in if prompted.\n",
    "3. Select the **Cloud Shell ([>_])** button.\n",
    "4. Choose:\n",
    "\n",
    "   * **PowerShell** environment\n",
    "   * **No storage**\n",
    "\n",
    "If Cloud Shell opens in Bash, switch to **PowerShell**.\n",
    "\n",
    "---\n",
    "\n",
    "### Switch to Classic Cloud Shell\n",
    "\n",
    "1. In Cloud Shell toolbar → **Settings**\n",
    "2. Select **Go to Classic version**\n",
    "\n",
    "This is required to use the built-in code editor.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Download and Prepare the Sample App\n",
    "\n",
    "### Clone the Repository\n",
    "\n",
    "```\n",
    "rm -r mslearn-ai-foundry -f\n",
    "git clone https://github.com/microsoftlearning/mslearn-ai-studio mslearn-ai-foundry\n",
    "```\n",
    "\n",
    "Navigate to the Python chat app:\n",
    "\n",
    "```\n",
    "cd mslearn-ai-foundry/labfiles/chat-app/python\n",
    "ls -a -l\n",
    "```\n",
    "\n",
    "Contents include:\n",
    "\n",
    "* Python app file\n",
    "* `.env` configuration file\n",
    "* Runtime and dependency files\n",
    "\n",
    "---\n",
    "\n",
    "### Set Up the Python Environment\n",
    "\n",
    "```\n",
    "python -m venv labenv\n",
    "./labenv/bin/Activate.ps1\n",
    "pip install -r requirements.txt azure-identity azure-ai-projects openai\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Configure Environment Variables\n",
    "\n",
    "Open the configuration file:\n",
    "\n",
    "```\n",
    "code .env\n",
    "```\n",
    "\n",
    "Replace:\n",
    "\n",
    "* `your_project_endpoint` → Your Foundry project endpoint **or model Target URI**\n",
    "* `your_model_deployment` → Deployment name (e.g., `gpt-4o`)\n",
    "\n",
    "Save and exit:\n",
    "\n",
    "* **CTRL+S** → Save\n",
    "* **CTRL+Q** → Quit\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Write Code to Chat with the Model\n",
    "\n",
    "### Open the App Code\n",
    "\n",
    "```\n",
    "code chat-app.py\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Add SDK References\n",
    "\n",
    "Under `# Add references`, add:\n",
    "\n",
    "```\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from openai import AzureOpenAI\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Initialize the Project Client\n",
    "\n",
    "Under `# Initialize the project client`:\n",
    "\n",
    "```\n",
    "project_client = AIProjectClient(            \n",
    "    credential=DefaultAzureCredential(\n",
    "        exclude_environment_credential=True,\n",
    "        exclude_managed_identity_credential=True\n",
    "    ),\n",
    "    endpoint=project_endpoint,\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Create the Chat Client\n",
    "\n",
    "Under `# Get a chat client`:\n",
    "\n",
    "```\n",
    "openai_client = project_client.get_openai_client(api_version=\"2024-10-21\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Initialize the System Prompt\n",
    "\n",
    "Under `# Initialize prompt with system message`:\n",
    "\n",
    "```\n",
    "prompt = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant that answers questions.\"}\n",
    "]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Get Chat Completions\n",
    "\n",
    "Under `# Get a chat completion` inside the loop:\n",
    "\n",
    "```\n",
    "prompt.append({\"role\": \"user\", \"content\": input_text})\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=model_deployment,\n",
    "    messages=prompt\n",
    ")\n",
    "completion = response.choices[0].message.content\n",
    "print(completion)\n",
    "prompt.append({\"role\": \"assistant\", \"content\": completion})\n",
    "```\n",
    "\n",
    "Save the file.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Sign In and Run the App\n",
    "\n",
    "### Authenticate with Azure\n",
    "\n",
    "```\n",
    "az login\n",
    "```\n",
    "\n",
    "Complete authentication in the browser and select the correct subscription if prompted.\n",
    "\n",
    "---\n",
    "\n",
    "### Run the Application\n",
    "\n",
    "```\n",
    "python chat-app.py\n",
    "```\n",
    "\n",
    "Example prompt:\n",
    "\n",
    "* *What is the fastest animal on Earth?*\n",
    "\n",
    "Try follow-up questions to verify chat history is retained.\n",
    "\n",
    "Enter `quit` to exit the app.\n",
    "\n",
    "---\n",
    "\n",
    "### Troubleshooting\n",
    "\n",
    "* If rate limits are exceeded, wait and retry\n",
    "* If quota is insufficient, the model may not respond\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Summary\n",
    "\n",
    "In this lab, you:\n",
    "\n",
    "* Deployed a model in a Foundry project\n",
    "* Retrieved project endpoints\n",
    "* Used the Foundry Python SDK\n",
    "* Built a stateful chat application\n",
    "* Authenticated using Azure credentials\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Clean Up\n",
    "\n",
    "To avoid unnecessary costs:\n",
    "\n",
    "1. Open the **Azure portal**\n",
    "2. Navigate to the **resource group** used in this lab\n",
    "3. Select **Delete resource group**\n",
    "4. Confirm deletion\n",
    "\n",
    "This removes all resources created for the exercise.\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Exam Takeaways\n",
    "\n",
    "* Foundry SDKs enable programmatic access to models\n",
    "* Projects expose endpoints used by client apps\n",
    "* DefaultAzureCredential is commonly used for auth\n",
    "* Chat history must be explicitly preserved in prompts\n",
    "* Model deployment region affects endpoint usage\n",
    "* Always delete unused resource groups\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
